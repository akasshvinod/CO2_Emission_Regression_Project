{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51b23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e1c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the preprocessed data..\n",
      "\n",
      "\n",
      "Final data verification:\n",
      "X_processed: (7390, 2148), dtype: float64\n",
      "y: (7390,), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the preprocessed data..\\n\")\n",
    "\n",
    "try:\n",
    "    # Method 1: Try loading from .npy files (recommended)\n",
    "    if os.path.exists('../data/processed/X_processed.npy'):\n",
    "        X_processed = np.load('../data/processed/X_processed.npy')\n",
    "        y = np.load('../data/processed/y.npy')\n",
    "    \n",
    "    # Method 2: Try loading from compressed .npz file\n",
    "    elif os.path.exists('../data/processed/processed_data.npz'):\n",
    "        data = np.load('../data/processed/processed_data.npz')\n",
    "        X_processed = data['X']\n",
    "        y = data['y']\n",
    "    \n",
    "    # Method 3: Fallback to original method (fixed)\n",
    "    else:\n",
    "        data = np.load('../data/processed/X_processed.npz', allow_pickle=True)\n",
    "        X_processed = data['arr_0']\n",
    "        if hasattr(X_processed, 'toarray'):  # If sparse matrix\n",
    "            X_processed = X_processed.toarray()\n",
    "        y = joblib.load('../data/processed/y.pkl')\n",
    "    \n",
    "    # Load preprocessor\n",
    "    preprocessor = joblib.load('../outputs/models/preprocessor.pkl')\n",
    "    \n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f' Error Loading files: {e}')\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f' Unexpected error: {e}')\n",
    "    exit()\n",
    "\n",
    "# Convert to proper numpy arrays if needed\n",
    "if not isinstance(X_processed, np.ndarray):\n",
    "    X_processed = np.array(X_processed)\n",
    "if not isinstance(y, np.ndarray):\n",
    "    y = np.array(y)\n",
    "\n",
    "print(f\"\\nFinal data verification:\")\n",
    "print(f\"X_processed: {X_processed.shape}, dtype: {X_processed.dtype}\")\n",
    "print(f\"y: {y.shape}, dtype: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90549740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Data split successful:\n",
      "Training set: (5912, 2148)\n",
      "Test set: (1478, 2148)\n",
      "y_train: (5912,)\n",
      "y_test: (1478,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_processed, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data split successful:\")\n",
    "    print(f\"Training set: {X_train.shape}\")\n",
    "    print(f\"Test set: {X_test.shape}\")\n",
    "    print(f\"y_train: {y_train.shape}\")\n",
    "    print(f\"y_test: {y_test.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in train_test_split: {e}\")\n",
    "    print(f\"X_processed type: {type(X_processed)}\")\n",
    "    print(f\"X_processed shape: {getattr(X_processed, 'shape', 'No shape attribute')}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2950d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.01),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ca6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n",
      " Linear Regression: R¬≤=0.9889, RMSE=6.1597, CV_R¬≤=0.9912\n",
      "\n",
      "Training Ridge Regression...\n",
      " Ridge Regression: R¬≤=0.9912, RMSE=5.4898, CV_R¬≤=0.9928\n",
      "\n",
      "Training Lasso Regression...\n",
      " Lasso Regression: R¬≤=0.9909, RMSE=5.5719, CV_R¬≤=0.9927\n",
      "\n",
      "Training Random Forest...\n",
      " Random Forest: R¬≤=0.9965, RMSE=3.4756, CV_R¬≤=0.9975\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "cv_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'MAE': mae,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2\n",
    "        }\n",
    "        cv_scores[name] = cv_score\n",
    "        \n",
    "        print(f\" {name}: R¬≤={r2:.4f}, RMSE={rmse:.4f}, CV_R¬≤={cv_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error training {name}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2604d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE SUMMARY (Sorted by R¬≤ Score)\n",
      "============================================================\n",
      "                         R2      RMSE       MAE\n",
      "Random Forest      0.996476  3.475618  1.828286\n",
      "Ridge Regression   0.991207  5.489794  3.028768\n",
      "Lasso Regression   0.990942  5.571918  3.054642\n",
      "Linear Regression   0.98893  6.159702   3.35824\n"
     ]
    }
   ],
   "source": [
    "performance_df = pd.DataFrame(results).T[['R2', 'RMSE', 'MAE']]\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE SUMMARY (Sorted by R¬≤ Score)\")\n",
    "print(\"=\"*60)\n",
    "print(performance_df.sort_values('R2', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d293d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = performance_df['R2'].idxmax()\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59652027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "BEST MODEL RESULTS\n",
      "==================================================\n",
      " Best Model: Random Forest\n",
      " R¬≤ Score: 0.996476\n",
      " RMSE: 3.475618\n",
      " MAE: 1.828286\n",
      " Cross-Validation R¬≤: 0.997471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"BEST MODEL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\" Best Model: {best_model_name}\")\n",
    "print(f\" R¬≤ Score: {r2_best:.6f}\")\n",
    "print(f\" RMSE: {rmse_best:.6f}\")\n",
    "print(f\" MAE: {mae_best:.6f}\")\n",
    "print(f\" Cross-Validation R¬≤: {cv_scores[best_model_name]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2158cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Best model (Random Forest) saved as best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('../outputs/models', exist_ok=True)\n",
    "joblib.dump(best_model, \"../outputs/models/best_model.pkl\")\n",
    "print(f\"\\nüíæ Best model ({best_model_name}) saved as best_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
