{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22d0962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a02b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the preprocessed data..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the preprocessed data..\\n\")\n",
    "\n",
    "try:\n",
    "    X_processed_data=np.load('../data/processed/X_processed.npz',allow_pickle=True)\n",
    "    X_processed=X_processed_data['arr_0'].item()\n",
    "    \n",
    "    y=joblib.load('../data/processed/y.pkl')\n",
    "    \n",
    "    preprocessor=joblib.load('../outputs/models/preprocessor.pkl')\n",
    "except FileNotFoundError as e:\n",
    "    print(f'Error Loading files : {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cca0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10545b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.01),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=42),\n",
    "    'SVR': SVR(kernel='rbf')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfc95de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - R2: 0.9889, RMSE: 6.1586, CV R2: 0.9912\n",
      "Ridge Regression - R2: 0.9913, RMSE: 5.4675, CV R2: 0.9928\n",
      "Lasso Regression - R2: 0.9909, RMSE: 5.5720, CV R2: 0.9927\n",
      "Random Forest - R2: 0.9965, RMSE: 3.4805, CV R2: 0.9975\n",
      "Gradient Boosting - R2: 0.9955, RMSE: 3.9115, CV R2: 0.9964\n",
      "XGBoost - R2: 0.9957, RMSE: 3.8258, CV R2: 0.9975\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 5912, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score 251.071888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 675\n",
      "[LightGBM] [Info] Number of data points in the train set: 4729, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score 251.730176\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 664\n",
      "[LightGBM] [Info] Number of data points in the train set: 4729, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score 250.556777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 675\n",
      "[LightGBM] [Info] Number of data points in the train set: 4730, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score 250.975053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 675\n",
      "[LightGBM] [Info] Number of data points in the train set: 4730, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score 251.207188\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 675\n",
      "[LightGBM] [Info] Number of data points in the train set: 4730, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score 250.890275\n",
      "LightGBM - R2: 0.9957, RMSE: 3.8597, CV R2: 0.9965\n",
      "SVR - R2: 0.9088, RMSE: 17.6833, CV R2: 0.9002\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "cv_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    cv_score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }\n",
    "    cv_scores[name] = cv_score\n",
    "    print(f\"{name} - R2: {r2:.4f}, RMSE: {rmse:.4f}, CV R2: {cv_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a10a43c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         R2      RMSE       MAE\n",
      "Random Forest      0.996466  3.480488  1.825813\n",
      "XGBoost             0.99573  3.825765  2.052024\n",
      "LightGBM           0.995654  3.859718  2.223702\n",
      "Gradient Boosting  0.995536  3.911544  2.576186\n",
      "Ridge Regression   0.991278  5.467512  3.026363\n",
      "Lasso Regression   0.990942  5.571954  3.054838\n",
      "Linear Regression  0.988934  6.158588  3.357782\n",
      "SVR                0.908768   17.6833  7.260604\n"
     ]
    }
   ],
   "source": [
    "performance_df = pd.DataFrame(results).T[['R2', 'RMSE', 'MAE']]\n",
    "print(performance_df.sort_values('R2', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aaa4344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Random Forest\n",
      "R2: 0.996466\n",
      "RMSE: 3.480488\n",
      "MAE: 1.825813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Step 1: Pick the best model based on R2\n",
    "best_model_name = performance_df['R2'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Step 2: Predict with best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Step 3: Evaluate performance\n",
    "r2 = r2_score(y_test, y_pred_best)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_best)) \n",
    "mae = mean_absolute_error(y_test, y_pred_best)\n",
    "\n",
    "# Step 4: Print results\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"R2: {r2:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAE: {mae:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3324d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved as best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model (RandomForest in your case)\n",
    "joblib.dump(best_model, \"../outputs/models/best_model.pkl\")\n",
    "\n",
    "print(\" Model saved as best_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
